{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the IAM role of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads keras libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates directory with keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls keras_model\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded model of feature extraction from disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 96, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 48, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 48, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 24, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3/conv3_1 (Conv2D)       (None, 24, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3/conv3_2 (Conv2D)       (None, 24, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 12, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv4/conv4_1 (Conv2D)       (None, 12, 8, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "conv4/conv4_2 (Conv2D)       (None, 12, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 6, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_ (Flatten)           (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "vggish_fc1/fc1_1 (Dense)     (None, 4096)              50335744  \n",
      "_________________________________________________________________\n",
      "vggish_fc1/fc1_2 (Dense)     (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "vggish_fc2 (Dense)           (None, 128)               524416    \n",
      "=================================================================\n",
      "Total params: 72,141,184\n",
      "Trainable params: 72,141,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "json_file = open('/home/ec2-user/SageMaker/keras_model/'+'sound_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('/home/ec2-user/SageMaker/keras_model/sound_model.h5')\n",
    "print(\"Loaded model of feature extraction from disk\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Keras model (sound extractor) to the TensorFlow ProtoBuf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# Note: This directory structure will need to be followed - see notes for the next section\n",
    "model_version = '1'\n",
    "export_dir = 'export/Servo/'+ model_version\n",
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "builder = builder.SavedModelBuilder(export_dir)\n",
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "    inputs={\"inputs\": loaded_model.input}, outputs={\"vgg_features\": loaded_model.output})\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    # Save the meta graph and variables\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess=sess, tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls export/Servo/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls export/Servo/1/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open('sound_extractor.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='sound_extractor.tar.gz', key_prefix='sound_extractor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an empty file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_model = TensorFlowModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/sound_extractor/sound_extractor.tar.gz',\n",
    "                                  role = role,\n",
    "                                  entry_point = 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "\n",
    "for file in my_bucket.objects.all():\n",
    "    print(file.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.c5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does same thing for classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('/home/ec2-user/SageMaker/keras_model/'+'sound_class.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('/home/ec2-user/SageMaker/keras_model/sound_class.h5')\n",
    "print(\"Loaded model of feature extraction from disk\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from keras import backend as K\n",
    "\n",
    "# Note: This directory structure will need to be followed - see notes for the next section\n",
    "model_version = '1'\n",
    "export_dir = 'export/Servo/'+ model_version\n",
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "builder = builder.SavedModelBuilder(export_dir)\n",
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "    inputs={\"inputs\": loaded_model.input}, outputs={\"output\": loaded_model.output})\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    # Save the meta graph and variables\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess=sess, tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls export/Servo/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls export/Servo/1/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open('sound_classifier.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='sound_classifier.tar.gz', key_prefix='sound_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "\n",
    "for file in my_bucket.objects.all():\n",
    "    print(file.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_model = TensorFlowModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/sound_classifier/sound_classifier.tar.gz',\n",
    "                                  role = role,\n",
    "                                  entry_point = 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download samples of acoustic scenes for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/record/1040168/files/TUT-acoustic-scenes-2017-evaluation.audio.1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip TUT-acoustic-scenes-2017-evaluation.audio.1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install resampy pysoundfile SoundFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import argparse\n",
    "import csv\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ec2-user/SageMaker/ml_osoai/audioset_sagemaker/audioset_feature_extractor')\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file = './TUT-acoustic-scenes-2017-evaluation/audio/10.wav'\n",
    "examples_batch = wavfile_to_examples(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate pareto latence and cost of AWS service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "fig.suptitle(\"Pareto optimum - Sound extractor\")\n",
    "df = pd.DataFrame({\n",
    "'cost': [4.627,0.311,0.538,1.075,1.267,0.134,0.526,0.33,1.271],\n",
    "'latence' : [496.53,791.06,560.83,501.68,536.8,498.23,543.46,518.53,536.46],\n",
    "'group': ['ml.p3.2xlarge','ml.m4.xlarge','ml.c5.2xlarge','ml.c5.4xlarge','ml.c4.4xlarge','ml.c5.large','ml.c5.large\\n ml.eia1.large','ml.c5.large\\n ml.eia1.medium','ml.c5.4xlarge\\n ml.eia1.medium']\n",
    "})\n",
    "#df['latence']=normalize(df['latence'].values)\n",
    "#sns.set_palette(sns.color_palette(\"hls\", 4))\n",
    "sns.set_style(\"darkgrid\")\n",
    "paper_rc = {'lines.linewidth': 3}\n",
    "sns.set_context(\"paper\", rc = paper_rc)\n",
    "p1=sns.scatterplot(x=\"cost\", y=\"latence\",data=df,marker=\"o\",s=75)\n",
    "p1.set_xlim(0.0, 5.0)\n",
    "#p1.set_ylim(0.0,1.0)\n",
    "p1.set_xlabel(\"Cost ($/h)\")\n",
    "p1.set_ylabel(\"Latence (ms)\")\n",
    "for line in range(0,df.shape[0]):\n",
    "    p1.text(df.cost[line]+0.02, df.latence[line]-10, df.group[line], horizontalalignment='right', size='medium',rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier based on Autopooling and BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autopool\n",
    "!pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/ec2-user/SageMaker/ml_osoai/audioset_sagemaker/audioset_feature_extractor')\n",
    "import classifier_model\n",
    "model = classifier_model.get_classifier_model(model_type='adaptative_pooling', model_path='/home/ec2-user/SageMaker/weights/md_50000_adap_iters.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from keras import backend as K\n",
    "\n",
    "# Note: This directory structure will need to be followed - see notes for the next section\n",
    "model_version = '1'\n",
    "export_dir = '/home/ec2-user/SageMaker/export/Servo/'+ model_version\n",
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "builder = builder.SavedModelBuilder(export_dir)\n",
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "    inputs={\"inputs\": model.input}, outputs={\"output\": model.output[0], \"t_output\":model.output[1]})\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    # Save the meta graph and variables\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess=sess, tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "    builder.save()\n",
    "import tarfile\n",
    "with tarfile.open('sound_classifier_adapt.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='sound_classifier_adapt.tar.gz', key_prefix='sound_classifier_adapt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an empty file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "\n",
    "for file in my_bucket.objects.all():\n",
    "    print(file.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_model = TensorFlowModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/sound_classifier_adapt/sound_classifier_adapt.tar.gz',\n",
    "                                  role = role,\n",
    "                                  entry_point = 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.c5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
